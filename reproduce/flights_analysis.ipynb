{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pathpy as pp\n",
    "import hypa\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import numpy as np\n",
    "from random import random\n",
    "import draw\n",
    "from itertools import cycle\n",
    "cols = cycle(plt.rcParams['axes.prop_cycle'].by_key()['color'])\n",
    "\n",
    "coupon_fname = '../data/coupons_2018_01-5percent.ngram'\n",
    "#coupon_fname = '../../debruijn-nets/data/flights/2019/coupons_2019_q1.ngram'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = pp.Paths()\n",
    "paths = paths.read_file(coupon_fname, frequency=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([k * v[1] for k,v in paths.path_lengths().items()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lambda_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = pp.HigherOrderNetwork(paths, k=1, separator=paths.separator)\n",
    "adj = net.adjacency_matrix(weighted=False).todense()\n",
    "w,wv = np.linalg.eig(adj)\n",
    "\n",
    "max(w).real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[max(w).real**k/3600 for k in range(2,5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second order network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hy = hypa.HypaPP.from_paths(paths, k=2, log=True, implementation='scipy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pnet_edges_sorted = sorted(hy.hypa_net.edges.items(), key = lambda kv: kv[1]['pval'])\n",
    "pnet_edges_set = set([x[0] for x in pnet_edges_sorted])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvals  = []\n",
    "for e,dat in pnet_edges_sorted:\n",
    "    pvals.append(dat['pval'])\n",
    "\n",
    "plt.hist(np.exp(pvals), bins=40, log=True)\n",
    "# plt.hist((np.exp(pvals),np.exp(pval1).flatten()), bins=40, log=True)\n",
    "plt.xlabel('Transition likelihood')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare the return flights to others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "probs_return = []\n",
    "probs_other = []\n",
    "for e,d in hy.hypa_net.edges.items():\n",
    "    # check if A==C in (A-B)->(B-C)        \n",
    "    if e[0].split(',')[0] == e[1].split(',')[1]:\n",
    "        probs_return.append(d['pval'])\n",
    "    else:\n",
    "        probs_other.append(d['pval'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import draw\n",
    "draw.set_style()\n",
    "\n",
    "\n",
    "print('# return transitions:\\t\\t{}'.format(len(probs_return)))\n",
    "print('# non-return transitions:\\t{}'.format(len(probs_other)))\n",
    "\n",
    "plt.hist((np.exp(probs_return), np.exp(probs_other)),  bins=16,\n",
    "         log=False, stacked=False, density=True, \n",
    "         label=('Return',# ({})'.format(len(probs_return)), \n",
    "                'Non-return'))\n",
    "plt.xlabel('HYPA(2) scores')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('output/flights-returns-diff.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for po in [0.05, 0.01, 0.001, 0.0001, 0.00001]:\n",
    "    pthr_o = np.log(1-po)\n",
    "    pthr_u = np.log(po)\n",
    "\n",
    "    over_return = np.sum(np.array(probs_return) > pthr_o)\n",
    "    under_return = np.sum(np.array(probs_return) <= pthr_u)\n",
    "\n",
    "    over_other = np.sum(np.array(probs_other) > pthr_o)\n",
    "    under_other = np.sum(np.array(probs_other) <= pthr_u)\n",
    "\n",
    "    print(\"{:.0e}\\t&\\t{:.3f}\\t&\\t{:.3f} \\\\\\\\\".format(po, over_return/len(probs_return), over_other/len(probs_other)))\n",
    "    #print(\"{:.0e}\\t&\\t{:.3f}\\t&\\t{:.3f} \\\\\\\\\".format(po, over_return, over_other))\n",
    "    print(\"\\t return \\t|\\t non-return\")\n",
    "    print(\"under \\t\\t over \\t| under \\t\\t over\")\n",
    "    print(\"{:.1e} \\t {:.3f} \\t| {:.1e} \\t\\t {:.3f}\".format(\n",
    "        under_return/len(probs_return), over_return/len(probs_return),\n",
    "        under_other/len(probs_other), over_other/len(probs_other) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "over_non_return = []\n",
    "for e,d in hy.hypa_net.edges.items():\n",
    "    # check if A!=C in (A-B)->(B-C)\n",
    "    if e[0].split(',')[0] != e[1].split(',')[1] and d['pval'] > pthr_o:\n",
    "        over_non_return.append([e, d[\"weight\"], d[\"xival\"], d['pval']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len(over_non_return))\n",
    "over_non_return = sorted(over_non_return, key=lambda x: x[3], reverse=True)\n",
    "over_non_return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distance-related hypotheses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopy.distance as gd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airpdat = pd.read_csv('../data/airport-codes.csv')\n",
    "\n",
    "isUS = (airpdat.iso_country == 'US')\n",
    "hasCoors = airpdat.coordinates.apply(lambda x: len(x) > 8)\n",
    "hasIATA = airpdat.iata_code.notnull()\n",
    "\n",
    "airpdat = airpdat[isUS & hasCoors & hasIATA]\n",
    "\n",
    "airpdat.coordinates = airpdat.coordinates.apply(\n",
    "    lambda x: gd.lonlat(*x.split(', ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iata_coord = {row['iata_code']: row['coordinates'] for idx, row in airpdat.iterrows()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for e,edat in hy.hypa_net.edges.items():\n",
    "    a = e[0].split(',')[0]\n",
    "    b = e[0].split(',')[1]\n",
    "    c = e[1].split(',')[1]\n",
    "\n",
    "    try:\n",
    "        ainf, binf, cinf = (iata_coord[i] for i in (a,b,c))\n",
    "    except KeyError:\n",
    "        continue\n",
    "\n",
    "    hy.hypa_net.edges[e]['dist12'] = gd.distance(ainf, binf).km\n",
    "    hy.hypa_net.edges[e]['dist23'] = gd.distance(binf, cinf).km\n",
    "    hy.hypa_net.edges[e]['dist13'] = gd.distance(ainf, cinf).km"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rel_dist(dat):\n",
    "    return dat['dist13']/(dat['dist12'] + dat['dist23'])\n",
    "    \n",
    "pval_vs_dist = []\n",
    "for e,dat in hy.hypa_net.edges.items():\n",
    "    if \"dist12\" in dat:\n",
    "        pval_vs_dist.append([compute_rel_dist(dat), dat['pval']])\n",
    "\n",
    "pval_vs_dist = np.array(pval_vs_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bins = 16\n",
    "dist_bins = np.arange(0,1+1/n_bins, 1/n_bins)\n",
    "p_binned = [[] for b in dist_bins]\n",
    "for rd,pv in pval_vs_dist:\n",
    "    p_binned[np.argmax(rd <= dist_bins)].append(pv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "po = pu = 0.05\n",
    "# po = 0.05 # alpha_u\n",
    "over_binned = [np.sum(np.array(b) > np.log(1-po))/len(b) for b in p_binned]\n",
    "under_binned = [np.sum(np.array(b) < np.log(pu))/len(b) for b in p_binned]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw.set_style()\n",
    "ccc = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "plt.rcParams['figure.figsize'] =  [4, 3.6]\n",
    "\n",
    "plt.plot(dist_bins, under_binned, 'o-', c=ccc[0])\n",
    "plt.xlabel(\"Distance efficiency, $\\\\frac{d(A,C)}{d(A,B) + d(B,C)}$\")\n",
    "plt.ylabel(\"Fraction under-represented\")\n",
    "plt.ylim((0, 1.05*max(under_binned)))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('output/rel-dist-underrep.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw.set_style()\n",
    "plt.rcParams['figure.figsize'] =  [4, 3.6]\n",
    "\n",
    "plt.plot(dist_bins, np.array(over_binned), 'o-', c=ccc[1])\n",
    "plt.xlabel(\"Distance efficiency, $\\\\frac{d(A,C)}{d(A,B) + d(B,C)}$\")\n",
    "plt.ylabel(\"Fraction over-represented\")\n",
    "plt.ylim((0.2, 1.05*max(over_binned)))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('output/rel-dist-overrep.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_length_balance(dat):\n",
    "    return (dat['dist12'] - dat['dist23'])/(dat['dist12'] + dat['dist23'])\n",
    "    \n",
    "pval_vs_lratio = []\n",
    "for e,dat in hy.hypa_net.edges.items():\n",
    "    if \"dist12\" in dat:\n",
    "        pval_vs_lratio.append([compute_length_balance(dat), dat['pval']])\n",
    "\n",
    "pval_vs_lratio = np.array(pval_vs_lratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pu = 0.01\n",
    "# po = 0.01\n",
    "draw.set_style()\n",
    "plt.rcParams['figure.figsize'] =  [4, 3.6]\n",
    "\n",
    "lru = (pval_vs_lratio[:,1] < np.log(pu))\n",
    "lro = (pval_vs_lratio[:,1] > np.log(1-po))\n",
    "mid = np.logical_and(~lru, ~lro)\n",
    "lrnoo = (pval_vs_lratio[:,1] < np.log(1-po))\n",
    "\n",
    "plt.hist((pval_vs_lratio[lru,0], pval_vs_lratio[lro,0]),\n",
    "         label=('Under','Over'),\n",
    "         bins=32, density=True)\n",
    "\n",
    "plt.xlabel(\"Distance balance, $\\\\frac{d(A,B) - d(B,C)}{d(A,B) + d(B,C)}$\")\n",
    "plt.ylabel(\"Density of HYPA(2) scores\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('output/distance-balance.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
