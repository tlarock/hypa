{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pathpy as pp\n",
    "import hypa\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import numpy as np\n",
    "from random import random\n",
    "import draw\n",
    "from itertools import cycle\n",
    "cols = cycle(plt.rcParams['axes.prop_cycle'].by_key()['color'])\n",
    "\n",
    "coupon_fname = \"coupons_2018_01-5percent\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-14 16:01:49 [Severity.INFO]\tReading ngram data ... \n",
      "2020-08-14 16:01:52 [Severity.INFO]\tfinished. Read 88539 paths with maximum length 10\n"
     ]
    }
   ],
   "source": [
    "paths = pp.Paths()\n",
    "paths = paths.read_file('../data/{}.ngram'.format(coupon_fname), frequency=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total path count: \t\t185871.0 \n",
      "[Unique / Sub paths / Total]: \t[88539.0 / 1380687.0 / 1566558.0]\n",
      "Nodes:\t\t\t\t382 \n",
      "Edges:\t\t\t\t6933\n",
      "Max. path length:\t\t10\n",
      "Avg path length:\t\t2.481656632825992 \n",
      "Paths of length k = 0\t\t0.0 [ 0.0 / 647139.0 / 647139.0 ]\n",
      "Paths of length k = 1\t\t29531.0 [ 4667.0 / 431737.0 / 461268.0 ]\n",
      "Paths of length k = 2\t\t92711.0 [ 33610.0 / 182686.0 / 275397.0 ]\n",
      "Paths of length k = 3\t\t14358.0 [ 10943.0 / 104699.0 / 119057.0 ]\n",
      "Paths of length k = 4\t\t44885.0 [ 34961.0 / 10543.0 / 55428.0 ]\n",
      "Paths of length k = 5\t\t2852.0 [ 2833.0 / 3305.0 / 6157.0 ]\n",
      "Paths of length k = 6\t\t1374.0 [ 1365.0 / 397.0 / 1771.0 ]\n",
      "Paths of length k = 7\t\t104.0 [ 104.0 / 133.0 / 237.0 ]\n",
      "Paths of length k = 8\t\t41.0 [ 41.0 / 36.0 / 77.0 ]\n",
      "Paths of length k = 9\t\t9.0 [ 9.0 / 12.0 / 21.0 ]\n",
      "Paths of length k = 10\t\t6.0 [ 6.0 / 0.0 / 6.0 ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "461268.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([k * v[1] for k,v in paths.path_lengths().items()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lambda_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56.5502833753289"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = pp.HigherOrderNetwork(paths, k=1, separator=paths.separator)\n",
    "adj = net.adjacency_matrix(weighted=False).todense()\n",
    "w,wv = np.linalg.eig(adj)\n",
    "\n",
    "max(w).real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8883151527305556, 50.234473613511504, 2840.7737180545573]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[max(w).real**k/3600 for k in range(2,5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second order network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the k=2 order Xi...\n",
      "Fitting Xi...\n",
      "rmse = 6977.366846733035\n",
      "rmse = 0.000977831644160762\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Hypergeometric' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-fd1c4a789804>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mhy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhypa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHypa\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstruct_hypa_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/git/hypa/hypa/hypa.py\u001b[0m in \u001b[0;36mconstruct_hypa_network\u001b[0;34m(self, k, log, sparsexi, redistribute, xifittol, baseline, constant_xi, verbose)\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mxival\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxicoo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxicoo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxicoo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreverse_name_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreverse_name_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m             \u001b[0madd_edge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxival\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxisum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madjsum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse_name_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompute_hypa\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_xi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_observations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_p\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/hypa/hypa/hypa.py\u001b[0m in \u001b[0;36madd_edge\u001b[0;34m(u, v, xival, xisum, adjsum, reverse_name_dict)\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0;31m#from rpy2.robjects.packages import importr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreverse_name_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreverse_name_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0mpval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_hypa\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madjacency\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxival\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxisum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madjsum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_p\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mxival\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/hypa/hypa/hypa.py\u001b[0m in \u001b[0;36mcompute_hypa\u001b[0;34m(self, obs_freq, xi, total_xi, total_observations, log_p)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \"\"\"\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimplementation\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'julia'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             \u001b[0mhy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHypergeometric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_observations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_xi\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtotal_observations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlog_p\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mlogcdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs_freq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Hypergeometric' is not defined"
     ]
    }
   ],
   "source": [
    "hy = hypa.Hypa(paths)\n",
    "hy.construct_hypa_network(k=2, log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pnet_edges_sorted = sorted(hy.hypa_net.edges.items(), key = lambda kv: kv[1]['pval'])\n",
    "pnet_edges_set = set([x[0] for x in pnet_edges_sorted])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvals  = []\n",
    "for e,dat in pnet_edges_sorted:\n",
    "    pvals.append(dat['pval'])\n",
    "\n",
    "plt.hist(np.exp(pvals), bins=40, log=True)\n",
    "# plt.hist((np.exp(pvals),np.exp(pval1).flatten()), bins=40, log=True)\n",
    "plt.xlabel('Transition likelihood')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare the return flights to others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_return = []\n",
    "probs_other = []\n",
    "for e,d in hy.hypa_net.edges.items():\n",
    "    # check if A==C in (A-B)->(B-C)\n",
    "    if e[0].split(',')[0] == e[1].split(',')[1]:\n",
    "        probs_return.append(d['pval'])\n",
    "    else:\n",
    "        probs_other.append(d['pval'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import draw\n",
    "draw.set_style()\n",
    "\n",
    "\n",
    "print('# return transitions:\\t\\t{}'.format(len(probs_return)))\n",
    "print('# non-return transitions:\\t{}'.format(len(probs_other)))\n",
    "\n",
    "plt.hist((np.exp(probs_return), np.exp(probs_other)),  bins=16,\n",
    "         log=False, stacked=False, density=True, \n",
    "         label=('Return',# ({})'.format(len(probs_return)), \n",
    "                'Non-return'))\n",
    "plt.xlabel('HYPA(2) scores')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('output/flights-returns-diff.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "po = 0.00001\n",
    "pthr_o = np.log(1-po)\n",
    "pthr_u = np.log(po)\n",
    "\n",
    "over_return = np.sum(np.array(probs_return) > pthr_o)\n",
    "under_return = np.sum(np.array(probs_return) <= pthr_u)\n",
    "\n",
    "over_other = np.sum(np.array(probs_other) > pthr_o)\n",
    "under_other = np.sum(np.array(probs_other) <= pthr_u)\n",
    "\n",
    "print(\"{:.0e}\\t&\\t{:.3f}\\t&\\t{:.3f} \\\\\\\\\".format(po, over_return/len(probs_return), over_other/len(probs_other)))\n",
    "\n",
    "print(\"\\t return \\t|\\t non-return\")\n",
    "print(\"under \\t\\t over \\t| under \\t\\t over\")\n",
    "print(\"{:.1e} \\t {:.3f} \\t| {:.1e} \\t\\t {:.3f}\".format(\n",
    "    under_return/len(probs_return), over_return/len(probs_return),\n",
    "    under_other/len(probs_other), over_other/len(probs_other) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "over_non_return = []\n",
    "for e,d in hy.hypa_net.edges.items():\n",
    "    # check if A!=C in (A-B)->(B-C)\n",
    "    if e[0].split(',')[0] != e[1].split(',')[1] and d['pval'] > pthr_o:\n",
    "        over_non_return.append([e, d[\"weight\"], d[\"xival\"], d['pval']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len(over_non_return))\n",
    "over_non_return = sorted(over_non_return, key=lambda x: x[3], reverse=True)\n",
    "over_non_return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distance-related hypotheses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopy.distance as gd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airpdat = pd.read_csv('../data/airport-codes.csv')\n",
    "\n",
    "isUS = (airpdat.iso_country == 'US')\n",
    "hasCoors = airpdat.coordinates.apply(lambda x: len(x) > 8)\n",
    "hasIATA = airpdat.iata_code.notnull()\n",
    "\n",
    "airpdat = airpdat[isUS & hasCoors & hasIATA]\n",
    "\n",
    "airpdat.coordinates = airpdat.coordinates.apply(\n",
    "    lambda x: gd.lonlat(*x.split(', ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iata_coord = {row['iata_code']: row['coordinates'] for idx, row in airpdat.iterrows()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read = True\n",
    "\n",
    "for e,edat in hy.hypa_net.edges.items():\n",
    "    a = e[0].split(',')[0]\n",
    "    b = e[0].split(',')[1]\n",
    "    c = e[1].split(',')[1]\n",
    "\n",
    "    try:\n",
    "        ainf, binf, cinf = (iata_coord[i] for i in (a,b,c))\n",
    "    except KeyError:\n",
    "        continue\n",
    "\n",
    "    hy.hypa_net.edges[e]['dist12'] = gd.distance(ainf, binf).km\n",
    "    hy.hypa_net.edges[e]['dist23'] = gd.distance(binf, cinf).km\n",
    "    hy.hypa_net.edges[e]['dist13'] = gd.distance(ainf, cinf).km"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rel_dist(dat):\n",
    "    return dat['dist13']/(dat['dist12'] + dat['dist23'])\n",
    "    \n",
    "pval_vs_dist = []\n",
    "for e,dat in hy.hypa_net.edges.items():\n",
    "    if \"dist12\" in dat:\n",
    "        pval_vs_dist.append([compute_rel_dist(dat), dat['pval']])\n",
    "\n",
    "pval_vs_dist = np.array(pval_vs_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bins = 16\n",
    "dist_bins = np.arange(0,1+1/n_bins, 1/n_bins)\n",
    "p_binned = [[] for b in dist_bins]\n",
    "for rd,pv in pval_vs_dist:\n",
    "    p_binned[np.argmax(rd <= dist_bins)].append(pv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "po = pu = 0.05\n",
    "# po = 0.05 # alpha_u\n",
    "over_binned = [np.sum(np.array(b) > np.log(1-po))/len(b) for b in p_binned]\n",
    "under_binned = [np.sum(np.array(b) < np.log(pu))/len(b) for b in p_binned]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw.set_style()\n",
    "ccc = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "plt.rcParams['figure.figsize'] =  [4, 3.6]\n",
    "\n",
    "plt.plot(dist_bins, under_binned, 'o-', c=ccc[0])\n",
    "plt.xlabel(\"Distance efficiency, $\\\\frac{d(A,C)}{d(A,B) + d(B,C)}$\")\n",
    "plt.ylabel(\"Fraction under-represented\")\n",
    "plt.ylim((0, 1.05*max(under_binned)))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('output/rel-dist-underrep.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw.set_style()\n",
    "plt.rcParams['figure.figsize'] =  [4, 3.6]\n",
    "\n",
    "plt.plot(dist_bins, np.array(over_binned), 'o-', c=ccc[1])\n",
    "plt.xlabel(\"Distance efficiency, $\\\\frac{d(A,C)}{d(A,B) + d(B,C)}$\")\n",
    "plt.ylabel(\"Fraction over-represented\")\n",
    "plt.ylim((0.2, 1.05*max(over_binned)))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('output/rel-dist-overrep.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_length_balance(dat):\n",
    "    return (dat['dist12'] - dat['dist23'])/(dat['dist12'] + dat['dist23'])\n",
    "    \n",
    "pval_vs_lratio = []\n",
    "for e,dat in hy.hypa_net.edges.items():\n",
    "    if \"dist12\" in dat:\n",
    "        pval_vs_lratio.append([compute_length_balance(dat), dat['pval']])\n",
    "\n",
    "pval_vs_lratio = np.array(pval_vs_lratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pu = 0.01\n",
    "# po = 0.01\n",
    "draw.set_style()\n",
    "plt.rcParams['figure.figsize'] =  [4, 3.6]\n",
    "\n",
    "lru = (pval_vs_lratio[:,1] < np.log(pu))\n",
    "lro = (pval_vs_lratio[:,1] > np.log(1-po))\n",
    "mid = np.logical_and(~lru, ~lro)\n",
    "lrnoo = (pval_vs_lratio[:,1] < np.log(1-po))\n",
    "\n",
    "plt.hist((pval_vs_lratio[lru,0], pval_vs_lratio[lro,0]),\n",
    "         label=('Under','Over'),\n",
    "         bins=32, density=True)\n",
    "\n",
    "plt.xlabel(\"Distance balance, $\\\\frac{d(A,B) - d(B,C)}{d(A,B) + d(B,C)}$\")\n",
    "plt.ylabel(\"Density of HYPA(2) scores\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('output/distance-balance.pdf')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
